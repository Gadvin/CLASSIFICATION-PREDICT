{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HACKTHON CHALENGE\n",
    "\n",
    "© Explore Data Science Academy\n",
    "\n",
    "## Honour Code\n",
    "\n",
    "I **YOUR NAME**, **YOUR SURNAME**, confirm - by submitting this document - that the solutions in this notebook are a result of my own work and that I abide by the EDSA honour code (https://drive.google.com/file/d/1QDCjGZJ8-FmJE3bZdIQNwnJyQKPhHZBn/view?usp=sharing).\n",
    "\n",
    "\n",
    "<br></br>\n",
    "\n",
    "<div align=\"center\" style=\"width: 600px; font-size: 80%; text-align: center; margin: 0 auto\">\n",
    "<img src=\"https://raw.githubusercontent.com/Explore-AI/Pictures/master/credit_card.jpg\"\n",
    "     alt=\"Learn good habits to avoid modeling debt\"\n",
    "     style=\"float: center; padding-bottom=0.5em\"\n",
    "     width=600px/>\n",
    "Learn good habits to avoid modeling debt... Photo by <a href=\"https://unsplash.com/@rupixen?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText\"> Rupixen.com </a> on Unsplash.\n",
    "</div>\n",
    "\n",
    "The structure of this notebook is as follows:\n",
    "\n",
    " - First, I will start off by loading and viewing the dataset.\n",
    " - I will see that the dataset has a mixture of both numerical and non-numerical features; that it contains values from different ranges; and that it contains a number of missing entries.\n",
    " - Based upon the observations above, I will preprocess the dataset to ensure the machine learning model we choose can make good predictions.\n",
    " - After our data is in good shape, I will do some exploratory data analysis to build our intuitions.\n",
    " - Finally, I will build a machine learning model that can predict the language using the text given\n",
    " \n",
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import f1_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Dataset\n",
    "I use the data from my gitHub Repository to train and test my model.\n",
    "\n",
    "    \n",
    "I will explore the variables within this dataset in the sections below. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading in the data\n",
    "\n",
    "First, loading and viewing the dataset. We find that since this data are confidential, the contributor of the dataset has anonymized the feature names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lang_id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xho</td>\n",
       "      <td>umgaqo-siseko wenza amalungiselelo kumaziko ax...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>xho</td>\n",
       "      <td>i-dha iya kuba nobulumko bokubeka umsebenzi na...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eng</td>\n",
       "      <td>the province of kwazulu-natal department of tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nso</td>\n",
       "      <td>o netefatša gore o ba file dilo ka moka tše le...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ven</td>\n",
       "      <td>khomishini ya ndinganyiso ya mbeu yo ewa maana...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  lang_id                                               text\n",
       "0     xho  umgaqo-siseko wenza amalungiselelo kumaziko ax...\n",
       "1     xho  i-dha iya kuba nobulumko bokubeka umsebenzi na...\n",
       "2     eng  the province of kwazulu-natal department of tr...\n",
       "3     nso  o netefatša gore o ba file dilo ka moka tše le...\n",
       "4     ven  khomishini ya ndinganyiso ya mbeu yo ewa maana..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Importing the train dataSet\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/Gadvin/CLASSIFICATION-PREDICT/main/train_set.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The train data set contains 2 feature:\n",
    "  - Lang_Id( The language ID)\n",
    "  - Text\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33000, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This data set has a total of 33,000 rows and two features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lang_id    0\n",
       "text       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset doesn't contain missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Mmasepala, fa maemo a a kgethegileng a letlele...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Uzakwaziswa ngokufaneleko nakungafuneka eminye...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Tshivhumbeo tshi fana na ngano dza vhathu.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Kube inja nelikati betingevakala kutsi titsini...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Winste op buitelandse valuta.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Ke feela dilense tše hlakilego, tša pono e tee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>&lt;fn&gt;(762010101403 AM) 1495 Final Gems Birthing...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Ntjhafatso ya konteraka ya mosebetsi: Etsa bon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>u-GEMS uhlinzeka ngezinzuzo zemithi yezifo ezi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>So, on occasion, are statistics misused.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>Janewari la ngwaga ofe kapa, dikholego tša gag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>Ntirho wa mfumo : ku aka swikolo swo ringana n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>Kl.(3) e emetswe ke k. 13 ya Molaotheo Tlhabol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>Tshabo le ho se sireletsehe hoo ho ile ha baka...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>Loko u nga ri na ntiyiso wa leswaku xiphiqo xa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>lokuthabatha inxaxheba kwiintshukumo neeprogra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>Icandelwana (2) lithathelwe indawo licandelo 9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>LaMatsebula Yebo Mtilankhatsa, uva kahle. Wona...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>Enige persoon wat 'n bepaling van hierdie vero...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>Minisi.a' zwi amba Minisi.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>00 en 16:00 natmaak nie.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>Muhwelelwa a nga kha d i newa ndaela ya uri a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>Afidavithi efungelwe eqinisekisa ukuthi ozalwa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>Rente ten opsigte van finansiële huurkontrakte.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>Ke maemo afe ao a lefelelwago ka tlase ga khol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>Ukukunika amandla ukuthi ungazinakekela kanjan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>O mila thambo ya fula.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>Die verbruiker moet ingelig word welke metode,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>Go kwešiša dikhoutu tše fapanego mo setatament...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>EAfrika Dzonga a ku ri na ku tluriwa ka timfan...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    index                                               text\n",
       "0       1  Mmasepala, fa maemo a a kgethegileng a letlele...\n",
       "1       2  Uzakwaziswa ngokufaneleko nakungafuneka eminye...\n",
       "2       3         Tshivhumbeo tshi fana na ngano dza vhathu.\n",
       "3       4  Kube inja nelikati betingevakala kutsi titsini...\n",
       "4       5                      Winste op buitelandse valuta.\n",
       "5       6  Ke feela dilense tše hlakilego, tša pono e tee...\n",
       "6       7  <fn>(762010101403 AM) 1495 Final Gems Birthing...\n",
       "7       8  Ntjhafatso ya konteraka ya mosebetsi: Etsa bon...\n",
       "8       9  u-GEMS uhlinzeka ngezinzuzo zemithi yezifo ezi...\n",
       "9      10           So, on occasion, are statistics misused.\n",
       "10     11  Janewari la ngwaga ofe kapa, dikholego tša gag...\n",
       "11     12  Ntirho wa mfumo : ku aka swikolo swo ringana n...\n",
       "12     13  Kl.(3) e emetswe ke k. 13 ya Molaotheo Tlhabol...\n",
       "13     14  Tshabo le ho se sireletsehe hoo ho ile ha baka...\n",
       "14     15  Loko u nga ri na ntiyiso wa leswaku xiphiqo xa...\n",
       "15     16  lokuthabatha inxaxheba kwiintshukumo neeprogra...\n",
       "16     17  Icandelwana (2) lithathelwe indawo licandelo 9...\n",
       "17     18  LaMatsebula Yebo Mtilankhatsa, uva kahle. Wona...\n",
       "18     19  Enige persoon wat 'n bepaling van hierdie vero...\n",
       "19     20                         Minisi.a' zwi amba Minisi.\n",
       "20     21                           00 en 16:00 natmaak nie.\n",
       "21     22  Muhwelelwa a nga kha d i newa ndaela ya uri a ...\n",
       "22     23  Afidavithi efungelwe eqinisekisa ukuthi ozalwa...\n",
       "23     24    Rente ten opsigte van finansiële huurkontrakte.\n",
       "24     25  Ke maemo afe ao a lefelelwago ka tlase ga khol...\n",
       "25     26  Ukukunika amandla ukuthi ungazinakekela kanjan...\n",
       "26     27                             O mila thambo ya fula.\n",
       "27     28  Die verbruiker moet ingelig word welke metode,...\n",
       "28     29  Go kwešiša dikhoutu tše fapanego mo setatament...\n",
       "29     30  EAfrika Dzonga a ku ri na ku tluriwa ka timfan..."
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Importing the test dataSet\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/Gadvin/CLASSIFICATION-PREDICT/main/test_set.csv')\n",
    "df.head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[480, 210]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_cleaning(df, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_**Expected Outputs:**_\n",
    "    \n",
    "\n",
    ">```\n",
    "data_cleaning(df, 0) == [480, 210]\n",
    "data_cleaning(df, 9) == [395, 295]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function to pre-process the data so that we can run it through the classifier. The function should:\n",
    "* Convert the non-numeric data into numeric using sklearn's ```labelEncoder``` \n",
    "* Drop the features 11 and 13 and convert the DataFrame to a NumPy array\n",
    "* Split the data into features and labels\n",
    "* Standardise the features using sklearn's ```MinMaxScaler```\n",
    "* Split the data into 80% training and 20% testing data.\n",
    "* Use the `train_test_split` method from `sklearn` to do this.\n",
    "* Set random_state to equal 42 for this internal method. \n",
    "\n",
    "_**Function Specifications:**_\n",
    "* Should take a dataframe as input.\n",
    "* Should return two `tuples` of the form `(X_train, y_train), (X_test, y_test)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### START FUNCTION\n",
    "def data_preprocess(df):  \n",
    "    # your code here\n",
    "    for word in df.select_dtypes('object').columns:\n",
    "        df[word ] = LabelEncoder().fit_transform(df[word ])\n",
    "        \n",
    "    df=df.drop([11,13],axis =1)    \n",
    "    X = df.drop(15, axis = 1).to_numpy()\n",
    "    y = df[15].to_numpy()\n",
    "    \n",
    "    minmax_scale = preprocessing.MinMaxScaler().fit(X)\n",
    "    df_minmax = minmax_scale.transform(X)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(df_minmax, y.astype(float) , test_size=0.2, random_state= 42)\n",
    "    \n",
    "    return (X_train, y_train), (X_test, y_test)\n",
    "\n",
    "   \n",
    "\n",
    "### END FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.25787966 0.48214286 1.         1.         0.42857143\n",
      "  0.33333333 0.         0.         0.         0.         0.\n",
      "  0.        ]]\n",
      "[1.]\n",
      "[[0.5        1.         0.05357143 0.66666667 0.33333333 0.42857143\n",
      "  0.33333333 0.         0.         1.         0.02985075 0.\n",
      "  0.00105   ]]\n",
      "[1.]\n"
     ]
    }
   ],
   "source": [
    "(X_train, y_train), (X_test, y_test) = data_preprocess(df)\n",
    "print(X_train[:1])\n",
    "print(y_train[:1])\n",
    "print(X_test[:1])\n",
    "print(y_test[:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_**Expected Outputs:**_\n",
    "\n",
    "```python\n",
    "(X_train, y_train), (X_test, y_test) = data_preprocess(df)\n",
    "print(X_train[:2])\n",
    "print(y_train[:2])\n",
    "print(X_test[:2])\n",
    "print(y_test[:2])\n",
    "```\n",
    "\n",
    "> ```\n",
    "[[1.         0.25787966 0.48214286 1.         1.         0.42857143\n",
    "  0.33333333 0.         0.         0.         0.         0.\n",
    "  0.        ]]\n",
    "[1.]\n",
    "[[0.5        1.         0.05357143 0.66666667 0.33333333 0.42857143\n",
    "  0.33333333 0.         0.         1.         0.02985075 0.\n",
    "  0.00105   ]]\n",
    "[1.]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have formatted our data, we can fit a model using sklearn's `LogisticRegression` class with solver 'lbfgs'. Write a function that will take as input `(X_train, y_train)` that we created previously, and return a trained model.\n",
    "\n",
    "_**Function Specifications:**_\n",
    "* Should take two numpy `arrays` as input in the form `(X_train, y_train)`.\n",
    "* The returned model should be fitted to the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "### START FUNCTION\n",
    "def train_model(X_train, y_train):\n",
    "    # your code here\n",
    "    l = LogisticRegression()\n",
    "    return l.fit(X_train, y_train)\n",
    "\n",
    "### END FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5068926456005394\n",
      "[[ 0.25237869 -0.22847881 -0.01779302  2.00977742  0.23903441 -0.29504922\n",
      "  -0.08952344 -0.83468871 -3.48756932 -1.07648711 -0.83688921  0.07860585\n",
      "  -1.3077735 ]]\n"
     ]
    }
   ],
   "source": [
    "lm = train_model(X_train, y_train)\n",
    "print(lm.intercept_[0])\n",
    "print(lm.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_**Expected Outputs:**_\n",
    "\n",
    "```python\n",
    "lm = train_model(X_train, y_train)\n",
    "print(lm.intercept_[0])\n",
    "print(lm.coef_)\n",
    "```\n",
    "```\n",
    "1.5068926456005878\n",
    "[[ 0.25237869 -0.22847881 -0.01779302  2.00977742  0.23903441 -0.29504922\n",
    "  -0.08952344 -0.83468871 -3.48756932 -1.07648711 -0.83688921  0.07860585\n",
    "  -1.3077735 ]]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3.2 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AUC - ROC curve is a performance measurement for classification problem at various thresholds settings. ROC is a probability curve and AUC represents degree or measure of separability. It tells how much model is capable of distinguishing between classes. Write a function which returns the roc auc score of your trained model when tested with the test set.\n",
    "\n",
    "_**Function Specifications:**_\n",
    "* Should take the fitted model and two numpy `arrays` `X_test, y_test` as input.\n",
    "* Should return a `float` of the roc auc score of the model. This number should be between zero and one.\n",
    "\n",
    "_**Hint**_  Use the positive class's probability as the score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "### START FUNCTION\n",
    "def roc_score(lm, X_test, y_test):\n",
    "    # your code here\n",
    "    pred_lm = lm.predict_proba(X_test)\n",
    "    aucs = roc_auc_score(y_test, pred_lm[:,1])\n",
    "    return aucs\n",
    "\n",
    "### END FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8865546218487395\n"
     ]
    }
   ],
   "source": [
    "print(roc_score(lm,X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_**Expected Outputs:**_\n",
    "    \n",
    "```python\n",
    "print(roc_score(lm,X_test,y_test))\n",
    "```\n",
    ">```\n",
    "0.8865546218487395\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function which calculates the Accuracy, Precision, Recall and F1 scores.\n",
    "\n",
    "_**Function Specifications:**_\n",
    "* Should take the fitted model and two numpy `arrays` `X_test, y_test` as input.\n",
    "* Should return a tuple in the form (`Accuracy`, `Precision`, `Recall`, `F1-Score`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "### START FUNCTION\n",
    "def scores(lm, X_test, y_test):\n",
    "    # your code here\n",
    "    \n",
    "    a = accuracy_score(y_test, lm.predict(X_test))\n",
    "    \n",
    "    p = precision_score(y_test, lm.predict(X_test))\n",
    "    \n",
    "    r = recall = recall_score(y_test, lm.predict(X_test))\n",
    "    \n",
    "    s = f1_score(y_test, lm.predict(X_test))\n",
    "    \n",
    "    return (a, p, r, s)\n",
    "    \n",
    "\n",
    "### END FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.833333\n",
      "Precision: 0.846154\n",
      "Recall: 0.808824\n",
      "F1 score: 0.827068\n"
     ]
    }
   ],
   "source": [
    "(accuracy, precision, recall, f1) = scores(lm, X_test, y_test)    \n",
    "\n",
    "print('Accuracy: %f' % accuracy)\n",
    "print('Precision: %f' % precision)\n",
    "print('Recall: %f' % recall)\n",
    "print('F1 score: %f' % f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_**Expected Outputs:**_\n",
    "```python\n",
    "(accuracy, precision, recall, f1) = scores(lm,X_test,y_test)\n",
    "    \n",
    "print('Accuracy: %f' % accuracy)\n",
    "print('Precision: %f' % precision)\n",
    "print('Recall: %f' % recall)\n",
    "print('F1 score: %f' % f1)\n",
    "```\n",
    "> ```\n",
    "Accuracy: 0.833333\n",
    "Precision: 0.846154\n",
    "Recall: 0.808824\n",
    "F1 score: 0.827068\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
